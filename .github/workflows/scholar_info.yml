name: Get Citation Data

on: 
  page_build: 
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/scholar_info.yml'
      - 'google_scholar_crawler/**'
  schedule:
    - cron:  '0 8 * * *'

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Dependencies
        run: |
          cd ./google_scholar_crawler
          pip install -r requirements.txt
          
      - name: Run Crawler
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}
        run: |
          cd ./google_scholar_crawler
          python main.py
          
      - name: Commit and Push
        run: |
          # Copy results to assets/results (where the website reads from)
          mkdir -p assets/results
          cp google_scholar_crawler/results/*.json assets/results/
          
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git add assets/results/*.json google_scholar_crawler/results/*.json
          git commit -m "Update Scholar citations (automated)" || echo "No changes to commit"
          git push origin main