---
title:          Bridging Classical and Quantum Computing for Next-Generation Language Models
date:           2025-08-25 00:02:00 -0400
selected:       true
pub:            "AAAI Symposium on Quantum Information & Machine Learning (QIML)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-custom badge-secondary">Conference</span>'
pub_date:       "2025"

abstract: >-
  Integrating Large Language Models (LLMs) with quantum computing is a critical challenge, hindered by the severe constraints of Noisy Intermediate-Scale Quantum (NISQ) devices, including barren plateaus and limited coherence. Current approaches often fail due to static quantum-classical partitioning. We introduce Adaptive Quantum-Classical Fusion (AQCF), the first framework to bridge this gap through dynamic, quantum-classical co-design. AQCF's core principle is real-time adaptation: it analyzes input complexity to orchestrate seamless transitions between classical and quantum processing. The framework features three key innovations: (1) entropy-driven adaptive circuits that circumvent barren plateaus; (2) quantum memory banks that unify classical attention with quantum state-based similarity retrieval; and (3) intelligent fusion controllers that allocate tasks for optimal performance. This architecture maintains full compatibility with classical Transformers while progressively incorporating quantum advantages. Experiments on sentiment analysis demonstrate that AQCF achieves competitive performance, significantly improves quantum resource efficiency, and operates successfully within typical NISQ constraints. By providing a seamless integration pathway, AQCF offers both immediate practical value on current quantum hardware and a clear evolution path toward mature Quantum LLMs.
  
cover:          assets/images/covers/aqcf.png
authors:
  - Yi Pan
  - Hanqi Jiang
  - Junhao Chen
  - Yiwei Li
  - Huaqin Zhao
  - Lin Zhao
  - Yohannes Abate
  - Yingfeng Wang†
  - Tianming Liu†
links:
  Paper: https://arxiv.org/abs/2508.07026
---
